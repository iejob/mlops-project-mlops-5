version: '3.8' # 도커 컴포즈 파일 버전(3.8 권장)

# ==============================
# Airflow 서비스 공통 anchor(템플릿)
# ==============================
x-airflow-common: &airflow-common
  # build: . # 기존의 'build: .' 명령어는 Dockerfile이 있는 디렉토리를 빌드 컨텍스트로 사용하므로 경로 오류가 발생합니다.
  build:
    context: .                                                                  # 빌드 컨텍스트를 프로젝트 루트 디렉토리(.)로 설정
    dockerfile: ${DOCKER_AIRFLOW}                                               # Dockerfile의 경로를 명시
  image: ${AIRFLOW_IMAGE_NAME:-apache/airflow:2.8.2}                            # Airflow 공식 이미지, 환경변수로 버전 지정 가능
  user: "1000:0"
  environment:
    AIRFLOW_UID: ${AIRFLOW_UID}                                                 # 컨테이너 내 실행 사용자 UID(기본값 50000)
    AIRFLOW_GID: ${AIRFLOW_GID}                                                 # 컨테이너 내 실행 사용자 GID(기본값 0)
    AIRFLOW_HOME: ${AIRFLOW_HOME}                                               # Airflow 홈 디렉토리(모든 실행 기준 경로)
    AIRFLOW__CORE__SQL_ALCHEMY_CONN: ${AIRFLOW__CORE__SQL_ALCHEMY_CONN}         # 내부 DB 연결(필수)
    AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW__CORE__FERNET_KEY}                     # Fernet 암호화 키(필수)
    AIRFLOW__CORE__EXECUTOR: ${AIRFLOW__CORE__EXECUTOR}                         # Executor 타입(Celery, Local 등)
    AIRFLOW__CELERY__BROKER_URL: ${AIRFLOW__CELERY__BROKER_URL}                 # Celery 브로커 URL(예: redis)
    AIRFLOW__CELERY__RESULT_BACKEND: ${AIRFLOW__CELERY__RESULT_BACKEND}         # Celery 결과 저장 Backend
    AIRFLOW__CORE__LOGGING_LEVEL: INFO                                          # 로그 레벨(INFO 고정)
    AIRFLOW__WEBSERVER__WEB_SERVER_PORT: ${AIRFLOW__WEBSERVER__WEB_SERVER_PORT} # Webserver 포트(8080)
    AIRFLOW__WEBSERVER__WEB_SERVER_HOST: ${AIRFLOW__WEBSERVER__WEB_SERVER_HOST} # Webserver 호스트(모든 IP에서 접근 가능)
    PYTHONPATH: /opt/airflow:/opt/airflow/scripts                               # Airflow 스크립트 경로 추가 
  env_file:
    - ${ENV_PATH}                                                                      # 민감정보, 환경변수 파일(${ENV_PATH})
    - ./.paths/paths${ENV_PATH}                                                        # 프로젝트별 경로 관리 환경변수 파일
  volumes:
    - ${DAGS_DIR}:/opt/airflow/dags                                             # DAG 파이썬 코드 저장 경로
    - ${LOGS_AIRFLOW_DIR}:/opt/airflow/logs                                     # Airflow 각종 로그 저장 경로
    - ${DATA_AIRFLOW_DIR}:/opt/airflow/data                                     # Airflow 데이터(공용)
    - ${DATA_RAW_DIR}:/opt/airflow/data/raw                                     # 원본(raw) 데이터 경로
    - ${DATA_PROCESSED_DIR}:/opt/airflow/data/processed                         # 전처리(피처) 데이터 경로
    - ${PLUGINS_AIRFLOW_DIR}:/opt/airflow/plugins                               # Airflow 플러그인(추가 코드 등)
    - ${DATA_AIRFLOW_TEMP_DIR}:/opt/airflow/data/temp                           # 임시 데이터 경로
    - ./scripts:/opt/airflow/scripts                                            # Airflow 스크립트 경로(파이썬 코드)
  networks:
    - mlops_network             # Airflow 전용 도커 네트워크(브리지)
  restart: on-failure             # 컨테이너 장애 시 재시작

# ==============================
# 서비스(컨테이너) 정의
# ==============================
services:
  # --------------------------------
  # Airflow Webserver(관리 UI)
  # --------------------------------
  webserver:
    <<: *airflow-common                       # 공통 설정 상속(anchor)
    command: >                                # webserver 실행(메인 UI)
      webserver --port 8080 --host 0.0.0.0
    user: "1000:0"
    ports:
      - "8080:8080"                           # 호스트:컨테이너 포트(8080)
    healthcheck:
      test: ["CMD-SHELL", "curl --fail http://localhost:8080/health || exit 1"] # Webserver 헬스체크
      interval: 10s                           # 체크 주기
      timeout: 10s                            # 타임아웃
      retries: 5                              # 최대 재시도
    restart: on-failure                       # 장애 시 재시작

  # --------------------------------
  # Airflow DB/권한 초기화(1회)
  # --------------------------------
  airflow-init:
    <<: *airflow-common
    command: bash -c "airflow db init && airflow users create --username admin --password admin --firstname admin --lastname admin --role Admin --email admin@example.com"
    user: "1000:0"

  # --------------------------------
  # Airflow Scheduler(DAG 실행 트리거)
  # --------------------------------
  scheduler:
    <<: *airflow-common                       # 공통 설정 상속(anchor)
    command: scheduler                        # 스케줄러 프로세스(DAG 자동 실행)
    user: "1000:0"
    healthcheck:
       test: ["CMD-SHELL", "airflow jobs check --job-type SchedulerJob --hostname airflow-scheduler"]
    restart: on-failure                       # 장애 시 재시작

  # --------------------------------
  # Airflow Worker(Celery)
  # --------------------------------
  worker:
    <<: *airflow-common                       # 공통 설정 상속(anchor)
    command: celery worker                    # 워커 프로세스(태스크 분산 실행)
    user: "1000:0"
    restart: on-failure                       # 장애 시 재시작

  # --------------------------------
  # Flower(Celery 작업 모니터링 UI)
  # --------------------------------
  flower:
    image: mher/flower:1.2.0                  # Flower 공식 이미지(버전 1.2.0)
    user: "1000:0"
    environment:
      CELERY_BROKER_URL: ${AIRFLOW__CELERY__BROKER_URL}         # 브로커 주소
      CELERY_RESULT_BACKEND: ${AIRFLOW__CELERY__RESULT_BACKEND} # 결과 저장소 주소
    ports:
      - "${FLOWER_PORT:-5555}:5555"           # 호스트:컨테이너 포트(5555 기본값)
    networks:
      - mlops_network                         # 동일 네트워크(통신)
    restart: on-failure                       # 장애 시 재시작

# ==============================
# Docker 볼륨 및 네트워크 정의
# ==============================
volumes:
  postgres_data:      # PostgreSQL 데이터 파일 영구 저장용 도커 볼륨

networks:
  mlops_network:      # Airflow, DB, Redis, Flower 등 모든 서비스가 연결되는 네트워크
    driver: bridge    # 브리지 네트워크(컨테이너 통신 전용)
