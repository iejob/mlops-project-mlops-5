version: '3.8' # 도커 컴포즈 파일 버전(3.8 권장)

# ==============================
# Airflow 서비스 공통 anchor(템플릿)
# ==============================
x-airflow-common: &airflow-common
  # build: . # 기존의 'build: .' 명령어는 Dockerfile이 있는 디렉토리를 빌드 컨텍스트로 사용하므로 경로 오류가 발생합니다.
  build:
    context: .                                                                  # 빌드 컨텍스트를 프로젝트 루트 디렉토리(.)로 설정
    dockerfile: ${DOCKER_AIRFLOW}                                               # Dockerfile의 경로를 명시
  image: ${AIRFLOW_IMAGE_NAME:-apache/airflow:2.8.2}                            # Airflow 공식 이미지, 환경변수로 버전 지정 가능
  user: "1000:0"
  environment:
    AIRFLOW_UID: ${AIRFLOW_UID}                                                 # 컨테이너 내 실행 사용자 UID(기본값 50000)
    AIRFLOW_GID: ${AIRFLOW_GID}                                                 # 컨테이너 내 실행 사용자 GID(기본값 0)
    AIRFLOW_HOME: ${AIRFLOW_HOME}                                               # Airflow 홈 디렉토리(모든 실행 기준 경로)
    AIRFLOW__CORE__SQL_ALCHEMY_CONN: ${AIRFLOW__CORE__SQL_ALCHEMY_CONN}         # 내부 DB 연결(필수)
    AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW__CORE__FERNET_KEY}                     # Fernet 암호화 키(필수)
    AIRFLOW__CORE__EXECUTOR: LocalExecutor                                      # 실행기(Executor) 설정(LocalExecutor)
    AIRFLOW__CORE__LOGGING_LEVEL: INFO                                          # 로그 레벨(INFO 고정)
    AIRFLOW__WEBSERVER__WEB_SERVER_PORT: ${AIRFLOW__WEBSERVER__WEB_SERVER_PORT} # Webserver 포트(8080)
    AIRFLOW__WEBSERVER__WEB_SERVER_HOST: ${AIRFLOW__WEBSERVER__WEB_SERVER_HOST} # Webserver 호스트(모든 IP에서 접근 가능)
    PYTHONPATH: /opt/airflow:/opt/airflow/scripts                               # Airflow 스크립트 경로 추가 
  env_file:
    - ${ENV_PATH}                                                                      # 민감정보, 환경변수 파일(${ENV_PATH})
    - ./.paths/paths${ENV_PATH}                                                        # 프로젝트별 경로 관리 환경변수 파일
  volumes:
    - ${DAGS_DIR}:/opt/airflow/dags                                             # DAG 파이썬 코드 저장 경로
    - ${LOGS_AIRFLOW_DIR}:/opt/airflow/logs                                     # Airflow 각종 로그 저장 경로
    - ${DATA_AIRFLOW_DIR}:/opt/airflow/data                                     # Airflow 데이터(공용)
    - ${DATA_RAW_DIR}:/opt/airflow/data/raw                                     # 원본(raw) 데이터 경로
    - ${DATA_PROCESSED_DIR}:/opt/airflow/data/processed                         # 전처리(피처) 데이터 경로
    - ${DATA_AIRFLOW_TEMP_DIR}:/opt/airflow/data/temp                           # 임시 데이터 경로
    - ./scripts:/opt/airflow/scripts                                            # Airflow 스크립트 경로(파이썬 코드)
  networks:
    - mlops_network             # Airflow 전용 도커 네트워크(브리지)
  restart: on-failure             # 컨테이너 장애 시 재시작
  depends_on:                     # 의존 서비스 준비될 때까지 대기
    postgres:
      condition: service_healthy  # postgres 서비스 health check 통과 후 시작

# ==============================
# 서비스(컨테이너) 정의
# ==============================
services:
  # --------------------------------
  # PostgreSQL(Airflow 내부 DB)
  # --------------------------------
  postgres:
    image: postgres:13                          # PostgreSQL 공식 이미지(버전 13)
    environment:
      POSTGRES_USER: ${POSTGRES_USER}           # DB 계정명
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}   # DB 비밀번호
      POSTGRES_DB: ${POSTGRES_DB}               # DB 이름
    ports:
      - ${DB_PORT}:${DB_PORT}                   # 호스트:컨테이너 포트(5432)
    volumes:
      - postgres_data:/var/lib/postgresql/data  # 데이터 파일을 로컬 볼륨에 영구 저장
    networks:
      - mlops_network                        # 동일 네트워크(통신)
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"] # DB 준비상태 체크
      interval: 5s                              # 체크 주기
      timeout: 5s                               # 타임아웃
      retries: 5                                # 최대 재시도
    restart: on-failure                         # 장애 시 재시작

  # --------------------------------
  # 모델 학습 및 추론 서비스
  # --------------------------------
  model_inference:
    build:
      context: .                                          # 빌드 컨텍스트를 상위 디렉토리로 설정
      dockerfile: ${DOCKER_MODEL_INFERENCE}               # Dockerfile 경로
    image: jkim1209/mlops-project:1.2.0                   # 이미지 이름 및 태그
    container_name: model_inference                       # 컨테이너 이름
    environment:
      DB_HOST: ${DB_HOST}
      DB_NAME: ${DB_NAME}
      DB_USER: ${DB_USER}
      DB_PASSWORD: ${DB_PASSWORD}
      DB_PORT: ${DB_PORT}

      TMDB_API_KEY: ${TMDB_API_KEY}
      TMDB_BASE_URL: ${TMDB_BASE_URL}

      S3_BUCKET_NAME: ${S3_BUCKET_NAME}
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      AWS_REGION: ${AWS_REGION}
    healthcheck:
      test: ["CMD-SHELL", "echo", "healthcheck"]
      interval: 1m30s
      timeout: 10s
      retries: 3
    networks:
      - mlops_network
    depends_on:
      - postgres                                        # PostgreSQL 준비 완료 후 시작   

  # --------------------------------
  # API 서비스
  # --------------------------------
  mlops-api:
    build:
      context: .
      dockerfile: ${DOCKER_API}
    image: jkim1209/mlops-api:1.0.2
    container_name: mlops-api
    ports:
      - "8000:8000"
    env_file:
      - ${ENV_PATH}
    environment:
      DB_HOST: ${DB_HOST}
      DB_PORT: ${DB_PORT}
      DB_NAME: ${DB_NAME}
      DB_USER: ${DB_USER}
      DB_PASSWORD: ${DB_PASSWORD}
    healthcheck:
      test: ["CMD-SHELL", "curl --fail http://localhost:8000/docs || exit 1"]  # /docs 엔드포인트 200 OK 확인
      interval: 10s                                     # 헬스체크 주기(10초)
      timeout: 10s                                      # 응답 대기(10초)
      retries: 3                                        # 최대 3번 재시도
      start_period: 20s                                 # 컨테이너 기동 후 최초 체크까지 대기(20초)
    networks:
      - mlops_network
    depends_on:
      - postgres                                        # PostgreSQL 준비 완료 후 시작

  # --------------------------------
  # Airflow Webserver(관리 UI)
  # --------------------------------
  webserver:
    <<: *airflow-common                       # 공통 설정 상속(anchor)
    command: >                                # webserver 실행(메인 UI)
      webserver --port 8080 --host 0.0.0.0
    user: "1000:0"
    ports:
      - "8080:8080"                           # 호스트:컨테이너 포트(8080)
    healthcheck:
      test: ["CMD-SHELL", "curl --fail http://localhost:8080/health || exit 1"] # Webserver 헬스체크
      interval: 10s                           # 체크 주기
      timeout: 10s                            # 타임아웃
      retries: 5                              # 최대 재시도
    restart: on-failure                       # 장애 시 재시작
    depends_on:
      - model_inference

  # --------------------------------
  # Airflow DB/권한 초기화(1회)
  # --------------------------------
  airflow-init:
    <<: *airflow-common
    command: bash -c "airflow db init && airflow users create --username admin --password admin --firstname admin --lastname admin --role Admin --email admin@example.com"
    user: "1000:0"
    depends_on:
      postgres:                     # PostgreSQL 준비 완료 후 실행
        condition: service_healthy
      model_inference:              # 모델 학습 서비스 준비 완료 후 실행
        condition: service_healthy


  # --------------------------------
  # Airflow Scheduler(DAG 실행 트리거)
  # --------------------------------
  scheduler:
    <<: *airflow-common                       # 공통 설정 상속(anchor)
    command: scheduler                        # 스케줄러 프로세스(DAG 자동 실행)
    user: "1000:0"
    healthcheck:
       test: ["CMD-SHELL", "airflow jobs check --job-type SchedulerJob --hostname airflow-scheduler"]
    restart: on-failure                       # 장애 시 재시작
    depends_on:
      - model_inference

# ==============================
# Docker 볼륨 및 네트워크 정의
# ==============================
volumes:
  postgres_data:      # PostgreSQL 데이터 파일 영구 저장용 도커 볼륨

networks:
  mlops_network:    # Airflow, DB, Redis, Flower 등 모든 서비스가 연결되는 네트워크
    driver: bridge    # 브리지 네트워크(컨테이너 통신 전용)
